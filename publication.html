<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>李籽溪 - 作品与项目</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@400;500;600&display=swap">
    <script src="scripts.js"></script>
    <style>
        .publication {
            margin-bottom: 40px;
            padding-bottom: 30px;
            border-bottom: 1px solid #2c3e50;
        }
        
        .publication:last-child {
            border-bottom: none;
        }
        
        .publication-content {
            overflow: hidden;
        }
        
        .publication-title {
            font-size: 1.3em;
            font-weight: bold;
            margin-bottom: 10px;
            color: #00b894;
            font-family: 'Fira Code', monospace;
        }
        
        .publication-authors {
            margin-bottom: 5px;
        }
        
        .publication-venue {
            font-style: italic;
            margin-bottom: 10px;
            color: #74b9ff;
        }
        
        .publication-links {
            margin-bottom: 15px;
        }
        
        .publication-links a {
            color: #0984e3;
            text-decoration: none;
            background-color: rgba(9, 132, 227, 0.1);
            padding: 2px 5px;
            border-radius: 3px;
            transition: background-color 0.2s;
        }
        
        .publication-links a:hover {
            background-color: rgba(9, 132, 227, 0.2);
        }
        
        .publication-abstract {
            margin-top: 15px;
            clear: both;
            line-height: 1.6;
        }
        
        .back-link {
            display: inline-block;
            margin-bottom: 30px;
            font-family: 'Fira Code', monospace;
            color: #0984e3;
        }
        
        @media (max-width: 600px) {
            .publication-img {
                float: none;
                display: block;
                margin: 0 auto 20px;
            }
        }
        
        code {
            background-color: #2d3436;
            color: #00b894;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Fira Code', monospace;
        }
        
        .publication.hidden-by-tag {
            display: none;
        }
    </style>
</head>
<body>
    <div class="terminal-header">
        <div class="terminal-buttons">
            <span class="terminal-btn red"></span>
            <span class="terminal-btn yellow"></span>
            <span class="terminal-btn green"></span>
        </div>
        <div class="terminal-title">lizixi@sunyatsenuniversity:~/projects</div>
    </div>
    
    <a href="index.html" class="back-link">← cd ..</a>
    
    <h1>$ ls ./projects</h1>
    
    <!-- 项目标签列表 -->
    <div class="tags-container">
        <h3 class="tags-title">按标签筛选：</h3>
        <ul class="tags-list">
            <li class="tag-item active" data-tag="all">全部 <span class="tag-count">(4)</span></li>
            <li class="tag-item" data-tag="ai">AI/机器学习 <span class="tag-count">(4)</span></li>
            <li class="tag-item" data-tag="nlp">自然语言处理 <span class="tag-count">(2)</span></li>
            <li class="tag-item" data-tag="model-compression">模型压缩 <span class="tag-count">(1)</span></li>
            <li class="tag-item" data-tag="sentiment-analysis">情感分析 <span class="tag-count">(2)</span></li>
            <li class="tag-item" data-tag="neural-network">神经网络 <span class="tag-count">(2)</span></li>
            <li class="tag-item" data-tag="chinese">中文处理 <span class="tag-count">(1)</span></li>
            <li class="tag-item" data-tag="mobile">移动应用 <span class="tag-count">(1)</span></li>
        </ul>
    </div>
    
    <div class="publication" data-tags="ai,model-compression,nlp,chinese">
        <div class="publication-content">
            <div class="publication-title">>_ MiniCodformer: 自研轻量级500M模型蒸馏框架</div>
            <div class="publication-authors"><strong>李籽溪</strong></div>
            <div class="publication-venue"><em>大模型压缩与优化</em>，2023-08-15</div>
            <div class="publication-links">
                <a href="https://github.com/lizixi-0x2F/MiniCodformer">代码</a> | 
                <a href="minicodformer.html">博客</a>
            </div>
        </div>
        <div class="publication-abstract">
            <strong>摘要：</strong> 该项目提供了一个简洁高效的知识蒸馏框架，专注于将大型语言模型（如Qwen3-8B）的知识蒸馏到中等规模模型(约500M参数)中。项目针对中文语言模型进行了特别优化，并支持使用中文维基百科数据进行预训练和蒸馏。
        </div>
        
        <div class="publication-abstract">
            <strong>主要特性：</strong>
            <ul>
                <li><strong>轻量化</strong>：参数量从8.3B减少到500M，减少约94%</li>
                <li><strong>高效训练</strong>：针对单GPU环境优化的内存高效训练框架</li>
                <li><strong>中文优化</strong>：专门针对中文语言模型进行了特别优化</li>
                <li><strong>性能优势</strong>：推理速度提升9倍，显存占用减少87.5%</li>
                <li><strong>保留能力</strong>：保持原始模型大部分能力，适用于通用NLP任务</li>
            </ul>
        </div>
        
        <div class="publication-abstract">
            <strong>技术实现：</strong>
            <ul>
                <li><strong>知识蒸馏策略</strong>：通过KL散度损失从教师模型传递知识</li>
                <li><strong>中文预训练</strong>：支持使用中文维基百科数据进行预训练</li>
                <li><strong>内存优化</strong>：词汇表不匹配处理、CPU分块处理、半精度训练</li>
                <li><strong>灵活架构</strong>：支持自定义模型架构，适应不同计算资源限制</li>
                <li><strong>多阶段训练</strong>：预训练、蒸馏两阶段处理</li>
            </ul>
        </div>
        
        <div class="publication-abstract">
            <strong>应用场景：</strong>
            <p>MiniCodformer适用于计算资源有限的环境，特别适合中文文本处理和生成任务。此外，还可用于模型蒸馏方法的快速实验与验证，以及作为知识蒸馏技术的教学与研究工具。</p>
        </div>
    </div>
    
    <div class="publication" data-tags="ai,nlp,sentiment-analysis,neural-network">
        <div class="publication-content">
            <div class="publication-title">>_ BiLingualSentimentMPS: 中英文情感分析模型</div>
            <div class="publication-authors"><strong>李籽溪</strong></div>
            <div class="publication-venue"><em>自然语言处理项目</em>，2025-05-14</div>
            <div class="publication-links">
                <a href="https://github.com/lizixi-0x2F/BiLingualSentimentMPS">代码</a> | 
                <a href="bilingual-sentiment.html">博客</a>
            </div>
        </div>
        <div class="publication-abstract">
            <strong>摘要：</strong> 该项目突破了传统情感分析的语言限制，同时支持中文和英文的情感极性（效价）和情感强度（唤醒度）分析，通过NCP-LTC创新架构提高预测精度，R²分数可达0.6+。
        </div>
        
        <div class="publication-abstract">
            <strong>主要功能：</strong>
            <ul>
                <li><strong>双语支持</strong>：同时支持中文和英文情感分析</li>
                <li><strong>双维度输出</strong>：提供效价（情感极性）和唤醒度（情感强度）的双维度分析</li>
                <li><strong>高效训练</strong>：支持批次内多次迭代，显著提升模型性能</li>
                <li><strong>资源友好</strong>：相比大型预训练模型，内存和计算需求更低</li>
                <li><strong>可视化分析</strong>：提供情感预测的置信度和关键词贡献可视化</li>
            </ul>
        </div>
        
        <div class="publication-abstract">
            <strong>技术实现：</strong>
            <ul>
                <li><strong>神经回路策略(NCP)</strong>：15%稀疏连接，模拟生物神经网络结构</li>
                <li><strong>液体时间常数网络(LTC)</strong>：可学习的时间常数(τ)，适应不同的时间尺度</li>
                <li><strong>混合训练策略</strong>：λ权重控制回归损失与生成损失的比例</li>
                <li><strong>训练数据</strong>：中文VA数据集与EmoBank英文数据集</li>
                <li><strong>评估指标</strong>：R²分数、RMSE、CCC一致性相关系数</li>
            </ul>
        </div>
        
        <div class="publication-abstract">
            <strong>项目亮点：</strong>
            <p>该项目不仅解决了跨语言情感分析的挑战，还探索了一种轻量高效的神经网络架构。通过神经回路策略和液体时间常数网络的创新组合，实现了在资源受限条件下的高精度情感分析。模型在中英文情感分析任务上表现出色，且保持了跨语言的一致性，同时计算资源需求显著低于大型预训练模型。</p>
        </div>
    </div>
    
    <div class="publication" data-tags="ai,sentiment-analysis,mobile">
        <div class="publication-content">
            <div class="publication-title">>_ MindHub: 心灵情绪日记应用</div>
            <div class="publication-authors"><strong>李籽溪</strong></div>
            <div class="publication-venue"><em>心理学 x 人工智能项目</em>，2025-05-05</div>
            <div class="publication-links">
                <a href="https://github.com/lizixi-0x2F/MindHub">代码</a>
            </div>
        </div>
        <div class="publication-abstract">
            <strong>摘要：</strong> MindHub是一款专注于情感分析和情绪管理的日记应用，帮助用户记录和分析自己的情绪变化。应用通过苹果原生的自然语言处理(NLP)技术，自动分析日记内容中的情感，提供直观的情绪可视化和洞察。
        </div>
        
        <div class="publication-abstract">
            <strong>主要功能：</strong>
            <ul>
                <li><strong>Apple情绪分析</strong>：采用苹果原生NLP框架分析日记内容，准确识别文本中的情绪类型和强度</li>
                <li><strong>情绪周报</strong>：自动生成每周情绪分析报告，包含情绪摘要、关键日记分析和个性化建议</li>
                <li><strong>自动情绪推断</strong>：根据分析结果自动推断用户心情，无需手动选择</li>
                <li><strong>情绪可视化</strong>：包括GitHub风格的日记活跃热图、情绪价效度-唤起度象限散点图和情绪变化趋势图</li>
                <li><strong>个性化洞察</strong>：根据日记内容提供情感洞察和情绪变化趋势分析</li>
                <li><strong>标签组织</strong>：支持为日记添加标签，便于分类和查找</li>
            </ul>
        </div>
        
        <div class="publication-abstract">
            <strong>技术实现：</strong>
            <ul>
                <li><strong>语言和框架</strong>：Swift 5.9, SwiftUI</li>
                <li><strong>UI组件</strong>：自定义SwiftUI视图，Chart框架绘制图表</li>
                <li><strong>情感分析</strong>：Apple NaturalLanguage框架进行情绪识别和分析</li>
                <li><strong>本地存储</strong>：用户数据本地存储，确保隐私安全</li>
                <li><strong>情绪模型</strong>：采用唤起度-效价二维模型分析情绪</li>
            </ul>
        </div>
        
        <div class="publication-abstract">
            <strong>项目亮点：</strong>
            <p>该项目结合了心理学原理和人工智能技术，在隐私保护的前提下为用户提供了情绪管理工具。特别是情绪象限图的实现，不仅能够显示情绪的正负性，还能展示情绪的激活程度，让用户更全面地了解自己的情绪状态。项目的所有分析都在设备本地完成，确保了用户隐私安全。</p>
        </div>
    </div>
    
    <div class="publication" data-tags="ai,neural-network">
        <div class="publication-content">
            <div class="publication-title">>_ LNNStackVM: 基于栈虚拟机的神经网络</div>
            <div class="publication-authors"><strong>李籽溪</strong></div>
            <div class="publication-venue"><em>个人项目</em>，2025-05-01</div>
            <div class="publication-links">
                <a href="https://github.com/lizixi-0x2F/LNNStackVM">代码</a> |
                <a href="https://github.com/lizixi-0x2F/LNNStackVM">演示</a>
            </div>
        </div>
        <div class="publication-abstract">
            <strong>摘要：</strong> 本项目使用PyTorch实现了一个液态时间常数(LTC)神经网络，用于近似函数sin(x) + 0.5*sin(3x)。训练好的模型被转换为字节码并在基于栈的虚拟机(VM)上执行。项目包括一个用于加速推理的基于C语言的高性能VM，展示了神经网络训练、基于ODE的建模和轻量级VM推理。
        </div>
        
        <div class="publication-abstract">
            <strong>主要功能：</strong>
            <ul>
                <li>使用PyTorch和torchdiffeq训练LTC神经网络</li>
                <li>将模型转换为基于栈的VM的字节码</li>
                <li>使用C语言编写的VM加速推理（比Python VM快10-100倍）</li>
                <li>直观比较PyTorch和C VM预测结果</li>
                <li>生成const_pool.npz、bytecode.bin和ltc_fit_result_c.png（包含C VM）</li>
            </ul>
        </div>
        
        <div class="publication-abstract">
            <strong>技术细节：</strong>
            <ul>
                <li><strong>软件要求：</strong> Python 3.8+，C编译器（如gcc）和make用于构建C VM</li>
                <li><strong>Python依赖：</strong> torch==2.4.1, torchdiffeq==0.2.4, numpy==1.26.4, matplotlib==3.9.2</li>
                <li><strong>架构：</strong> 项目包含Python VM和字节码编译器架构，C VM遵循类似的结构但用C实现以提高性能</li>
                <li><strong>性能：</strong> C VM：约5-50微秒/调用，Python VM：约500-1000微秒/调用</li>
            </ul>
        </div>
    </div>
    
    <a href="index.html" class="back-link">← cd ..</a>
    
    <div class="terminal-footer">
        <p class="typing-effect">$ ls -la ./projects</p>
    </div>
</body>
</html> 